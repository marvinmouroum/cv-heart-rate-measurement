{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cv-heart-rate-measurement.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NeG8b11c8351"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marvinmouroum/cv-heart-rate-measurement/blob/master/cv_heart_rate_measurement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yPlqJBezCi4H"
      },
      "source": [
        "# Face detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRuoy4ARqQQ0",
        "colab_type": "text"
      },
      "source": [
        "### Initialize the Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r5RaNFXcCTVe",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import drive as gdrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dxd9JfOXDeNe",
        "outputId": "80083fae-b924-4025-c70c-c94e28b8d412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "gdrive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Project/'\n",
        "source_path = 'gdrive/My Drive/cohface/'\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PpKV4LRdCoeg",
        "colab": {}
      },
      "source": [
        "# Define paths\n",
        "prototxt_path = os.path.join(root_path + 'deploy.prototxt')\n",
        "caffemodel_path = os.path.join(root_path + 'weights.caffemodel')\n",
        "\n",
        "prototxt_path_id = '1-zfDOBY5fVcEzwii2JlrIDFyhLyvu5m5'\n",
        "caffemodel_path_id = '1jxuFoSukXr78rLfBgkLwn2qiWNUfoONf'\n",
        "image_id = '1wb8whYMorQNU2YvmHZsZGFeUTDc-95DN'\n",
        "\n",
        "downloaded = drive.CreateFile({'id': prototxt_path_id})\n",
        "downloaded.GetContentFile('deploy.prototxt')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': caffemodel_path_id})\n",
        "downloaded.GetContentFile('weights.caffemodel')\n",
        "\n",
        "# Read the model\n",
        "model = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NeG8b11c8351"
      },
      "source": [
        "### Proof of Concept\n",
        "\n",
        "Not needed for running for the detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jgKG3CzNHfDJ",
        "outputId": "988590c8-904f-42cb-d616-83c4eb4113e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls gdrive/My\\ Drive/Project"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deploy.prototxt  example.jpg  weights.caffemodel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RAi_gPq0CwCy",
        "outputId": "763a725a-e7d2-4e22-863a-cb66a8d36654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create directory 'updated_images' if it does not exist\n",
        "if not os.path.exists('updated_images'):\n",
        "\tprint(\"New directory created\")\n",
        "\tos.makedirs('updated_images')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New directory created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jbib6vYrCwlA",
        "outputId": "33c6dfd8-e049-4330-fc8e-10de15c97d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create directory 'faces' if it does not exist\n",
        "if not os.path.exists('faces'):\n",
        "\tprint(\"New directory created\")\n",
        "\tos.makedirs('faces')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New directory created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bBV29KjSLd7y",
        "outputId": "41de866b-4107-48a4-baca-9c9c8b83ce7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'images': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "99zPtf5kC234",
        "outputId": "c8dd1e5d-6eca-4cf9-a112-1c60bdae9368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# Loop through all images and save images with marked faces\n",
        "for file in os.listdir('images'):\n",
        "\tfile_name, file_extension = os.path.splitext(file)\n",
        "\tif (file_extension in ['.png','.jpg']):\n",
        "\t\tprint(\"Image path: {}\".format('images/' + file))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8bf837c853c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_extension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfile_extension\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image path: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wqjpDFJVC5FV",
        "colab": {}
      },
      "source": [
        "image = cv2.imread('images/' + file)\n",
        "\n",
        "(h, w) = image.shape[:2]\n",
        "blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "\n",
        "model.setInput(blob)\n",
        "detections = model.forward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KEH4wDdxC8AL",
        "colab": {}
      },
      "source": [
        "# Create frame around face\n",
        "for i in range(0, detections.shape[2]):\n",
        "  box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "  (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "  confidence = detections[0, 0, i, 2]\n",
        "\n",
        "  # If confidence > 0.5, show box around face\n",
        "  if (confidence > 0.5):\n",
        "    cv2.rectangle(image, (startX, startY), (endX, endY), (255, 255, 255), 2)\n",
        "\n",
        "cv2.imwrite('updated_images/' + file, image)\n",
        "print(\"Image \" + file + \" converted successfully\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TrMDH_cQDDP8",
        "colab": {}
      },
      "source": [
        "count = 0\n",
        "# Identify each face\n",
        "for i in range(0, detections.shape[2]):\n",
        "  box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "  (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "  confidence = detections[0, 0, i, 2]\n",
        "\n",
        "  # If confidence > 0.5, save it as a separate file\n",
        "  if (confidence > 0.5):\n",
        "    count += 1\n",
        "    frame = image[startY:endY, startX:endX]\n",
        "    cv2.imwrite('faces/' + str(i) + '_' + file, frame)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5JYmD2i4New2",
        "colab": {}
      },
      "source": [
        "!ls updated_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5WLdBEaLNk29",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "display(Image('updated_images/image.jpg'))\n",
        "display(Image('faces/0_image.jpg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dOZyGFX_RU0c",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id': '10d5-_YC2lX09LfnbbvraW0GoAKeqXUDu'})\n",
        "downloaded.GetContentFile('videos/data.avi')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3GudD3Ta8-jK"
      },
      "source": [
        "## Video Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdw6WrXnlI5x",
        "colab_type": "text"
      },
      "source": [
        "### This sections creates a local document structure in order to \n",
        "\n",
        "*   save a video locally in *temp_video*\n",
        "*   extract the face and save the image with bounding box locally in *bounding*\n",
        "*   extract the face and save it in a specified folder *faces/videoID*\n",
        "*   resize the face and save it in the directory *resized/videoID\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA1A-VGEmgIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This will clean the creates data\n",
        "def clean(temp='temp_video',bound='bounding',faces='faces',resized='resized'):\n",
        "  !rm -r $temp\n",
        "  !rm -r $bound\n",
        "  !rm -r $faces\n",
        "  !rm -r $resized \n",
        "\n",
        "#This will create all the necessary directories in order to perform the preprocessing\n",
        "def create_infrastructure(temp='temp_video',bound='bounding',faces='faces',resized='resized'):\n",
        "  !mkdir $temp\n",
        "  !mkdir $bound\n",
        "  !mkdir $faces\n",
        "  !mkdir $resized\n",
        "  !mkdir 'gdrive/My Drive/cohface/frames'\n",
        "\n",
        "#This will copy a video from the drive in the respective directory and create a folder dedicated to it's id\n",
        "def getVideo(path,id,faces='faces',bound='bounding',resized='resized',temp='temp_video'):\n",
        "  !mkdir $faces/$id\n",
        "  !mkdir $bound/$id\n",
        "  !mkdir $resized/$id\n",
        "  filetype = path.split('.')[-1]\n",
        "  target   = \"'\" + temp + '/' + id + '.' + filetype + \"'\"\n",
        "  source   = \"'\" + path + \"'\"\n",
        "  #print(\"!cp\" + \" \" + source + \" \" + target)\n",
        "  !cp $path $target\n",
        "  return temp + '/' + id + '.' + filetype"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKxLOyZCEBew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_img(img,destination):\n",
        "  # Create square images from pepes by adding black margins preserving original aspect ratio\n",
        "  #Importing modules opencv + numpy\n",
        "  import cv2\n",
        "  import numpy as np\n",
        "\n",
        "  w = 128\n",
        "  h = 192\n",
        "\n",
        "  #Reading an image (you can use PNG or JPG)\n",
        "  img = cv2.imread(img)\n",
        "\n",
        "  if(img.shape[0] > h or img.shape[1] > w):\n",
        "    #print(\"bigger image detected\")\n",
        "    img = cv2.resize(img,(w,h))\n",
        "\n",
        "  if img is None:\n",
        "    return False\n",
        "\n",
        "  #Creating a dark square with NUMPY  \n",
        "  f = np.zeros((h,w,3),np.uint8)\n",
        "\n",
        "  #Getting the centering position\n",
        "  ax,ay = (w - img.shape[1])//2,(h - img.shape[0])//2\n",
        "\n",
        "  #Pasting the 'image' in a centering position\n",
        "  f[ay:img.shape[0]+ay,ax:ax+img.shape[1]] = img\n",
        "  \n",
        "\n",
        "  #Saving the image\n",
        "  f = cv2.resize(f,(w,h),interpolation=cv2.INTER_NEAREST)\n",
        "  cv2.imwrite(destination,f)\n",
        "  cv2.destroyAllWindows() \n",
        "  return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6ynbTkvZ6QwC",
        "colab": {}
      },
      "source": [
        "def find_face(image,id,fileID,bound='bounding',faces='faces'):\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  (h, w) = image.shape[:2]\n",
        "  blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "\n",
        "  model.setInput(blob)\n",
        "  detections = model.forward()\n",
        "  # Create frame around face\n",
        "  for i in range(0, detections.shape[2]):\n",
        "    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "    (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "    confidence = detections[0, 0, i, 2]\n",
        "\n",
        "    # If confidence > 0.5, show box around face\n",
        "    if (confidence > 0.5):\n",
        "      cv2.rectangle(image, (startX, startY), (endX, endY), (255, 255, 255), 2)\n",
        "      #print(endX-startX)\n",
        "      #print(endY-startY)\n",
        "    \n",
        "  cv2.imwrite( bound + '/' + id + '/' + fileID + '.png', image)\n",
        "\n",
        "    # Identify each face\n",
        "  for i in range(0, detections.shape[2]):\n",
        "    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "    (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "    confidence = detections[0, 0, i, 2]\n",
        "\n",
        "    # If confidence > 0.5, save it as a separate file\n",
        "    if (confidence > 0.5):\n",
        "      count += 1\n",
        "      frame = image[startY:endY, startX:endX]\n",
        "      #print(faces + '/' + id + '/' + fileID + '.png')\n",
        "      cv2.imwrite( faces + '/' + id + '/' + fileID + '.png', frame)\n",
        "      #cv2_imshow(frame)\n",
        "      resize_img(faces + '/' + id + '/' + fileID + '.png','resized/' + id + '/' + fileID + '.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "73LJ5-kWJEA3",
        "colab": {}
      },
      "source": [
        "def analyze_video(video,id,temp='temp_video'):\n",
        "\n",
        "  # load video stream\n",
        "  VIDEO_STREAM =  temp + '/' + video\n",
        "\n",
        "  # Initialize the video stream and pointer to output video file\n",
        "  vs = cv2.VideoCapture(VIDEO_STREAM)\n",
        "  writer = None\n",
        "  vs.set(cv2.CAP_PROP_POS_FRAMES, 1);\n",
        "  i = 0\n",
        "  while i < 20000:\n",
        "    # read the next frame from the file\n",
        "    (grabbed, frame) = vs.read()\n",
        "    i += 1\n",
        "    # If the frame was not grabbed, then we have reached the end\n",
        "    # of the stream\n",
        "    if not grabbed:\n",
        "      print(\"Not grabbed.\")\n",
        "      break;\n",
        "    newID = id + str(i)\n",
        "    find_face(frame,id,newID)\n",
        "    if i%100 == 0:\n",
        "      print(i)\n",
        "    #break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWLaQh6epZuf",
        "colab_type": "text"
      },
      "source": [
        "### This section generates frames only of the face and saves them in a folder on the drive and local storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v3Fj3puONz0W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "63c55b49-3e72-48bd-c899-ad9635a69660"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "myid = '1_0'\n",
        "clean()\n",
        "create_infrastructure()\n",
        "filepath = getVideo('gdrive/My\\ Drive/cohface/1/0/data.avi',myid)\n",
        "filename = filepath.split(\"/\")[-1]\n",
        "analyze_video(filename,myid)\n",
        "\n",
        "destination = 'gdrive/My\\ Drive/cohface/frames/' + myid\n",
        "_destination = \"'\" + 'gdrive/My Drive/cohface/frames/' + myid + \"'\" \n",
        "_source = \"'resized/\"+myid+\"/.'\"\n",
        "!mkdir $destination\n",
        "!cp -a $_source $_destination\n"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘gdrive/My Drive/cohface/frames’: File exists\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "Not grabbed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD804V2Dku_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getVideos(random, vtype, nb, path, videosPaths):\n",
        "    if nb > len(videosPaths):\n",
        "      for file in os.listdir(path): # Get files and directories of the directory\n",
        "          _, currVidType = os.path.splitext(file)\n",
        "          if os.path.isdir(file): # This is a directory\n",
        "              getVideos(random, vtype, nb, path+'/'+file, videosPaths) \n",
        "          elif currVidType == '.'+vtype: # This is a file with the good video type\n",
        "              videosPaths.append(path+'/'+file)\n",
        "    return videosPaths "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1zRQ2ekku_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def script(random, vtype, nb, directories):\n",
        "  videosPaths = []\n",
        "  if len(directories)==0:\n",
        "    currentdirpath = os.getcwd()\n",
        "    videosPaths = getVideos(random, vtype, nb, currentdirpath, videosPaths)\n",
        "  else: \n",
        "    # there is no directory\t \n",
        "    for i in range(0,len(directories)):\n",
        "        videosPaths += getVideos(random, vtype, nb, directories[i],videosPaths)  \n",
        "       \n",
        "  return videosPaths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WOvexQEzgsIt",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfMxqC7mppRn",
        "colab_type": "text"
      },
      "source": [
        "## Here will be the dataloader that organizes the dataset for our training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIQyqZbFmZii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "2279b0c4-3cab-4b91-b5fe-7486f99b029d"
      },
      "source": [
        "import h5py\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class HDF5Dataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, file_path):\n",
        "        super(HDF5Dataset, self).__init__()\n",
        "        h5_file = h5py.File(file_path)\n",
        "        self.data = h5_file.get('data')\n",
        "        self.target = h5_file.get('label')\n",
        "\n",
        "    def __getitem__(self, index):            \n",
        "        return (torch.from_numpy(self.data[index,:,:,:]).float(),\n",
        "                torch.from_numpy(self.target[index,:,:,:]).float())\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "#!cp 'gdrive/My Drive/cohface/1/0/data.hdf5' 'temp_video/test.hdf5'\n",
        "dataset = HDF5Dataset('temp_video/test.hdf5')\n",
        "print(dataset)"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-250-1892347d294f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#!cp 'gdrive/My Drive/cohface/1/0/data.hdf5' 'temp_video/test.hdf5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDF5Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp_video/test.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-250-1892347d294f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         return (torch.from_numpy(self.data[index,:,:,:]).float(),\n\u001b[0m\u001b[1;32m     15\u001b[0m                 torch.from_numpy(self.target[index,:,:,:]).float())\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EZVUDlbku_U",
        "colab_type": "text"
      },
      "source": [
        "- First argument (mandatory) : random (0) or not random (1) \n",
        "- Second argument (mandatory) : the type of the video (avi, mp4, ...) \n",
        "- Third argument (mandatory) : number of videos wanted (if it's 0 or more than the amount of all the videos : all of them will be taken) \n",
        "- Other arguments : the list of directories or a directory that we want to look into\n",
        "\n",
        "If there is a directory inside of the one given in the path it will be open as well.\n",
        "\n",
        "If there isn't a path given, we will look in the current directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COzIxkqZku_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "script(0, 'avi', 2, '')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}